{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28742238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# load from .env file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from include.db.connections import get_master_db_connection\n",
    "from include.transform.client_data_transform import generate_address_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c98fba",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline\n",
    "\n",
    "The purpose of this pipeline is to allow for uploads of additional pool addresses to the Pool database. \n",
    "\n",
    "Steps are as follows:\n",
    "\n",
    "1. Get the given csv file.\n",
    "2. Assert required column set.\n",
    "3. Nan Checks on required columns, rejecting failing rows.\n",
    "4. Validity check on postal code column. \n",
    "5. lat lon validation (detect massive outliers and remove). \n",
    "6. Properties internal de-duplication\n",
    "7. Properties from db de-duplication\n",
    "8. Properties upload. \n",
    "9. Pool objectes upload. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3883f",
   "metadata": {},
   "source": [
    "## Step 1,2: CSV Ingestion Column Set Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a375221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_csv_data(path):\n",
    "    required_columns = [ 'address_number', 'municipality', 'lat',\n",
    "       'lon', 'postal_code', 'street_name', 'province_state', 'country',\n",
    "       'geom']\n",
    "\n",
    "    additional_columns = ['address_id', 'pool_type']\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    def check_required_columns(df, required_columns):\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "        return True\n",
    "\n",
    "    def has_additional_columns(df, additional_columns):\n",
    "        present_additional_columns = [col for col in additional_columns if col in df.columns]\n",
    "        return present_additional_columns\n",
    "\n",
    "\n",
    "    def create_additional_column_stubs(df):\n",
    "        #check the df does not have address_id\n",
    "        if 'address_id' not in df.columns:\n",
    "            df['address_id'] = generate_address_id()\n",
    "        \n",
    "\n",
    "        if 'pool_type' not in df.columns:\n",
    "            df['pool_type'] = None\n",
    "        return df\n",
    "\n",
    "\n",
    "    has_required = check_required_columns(df, required_columns)\n",
    "    present_additional = has_additional_columns(df, additional_columns)\n",
    "\n",
    "    if not has_required:\n",
    "        raise ValueError(\"DataFrame does not have all required columns.\")\n",
    "\n",
    "    if not present_additional:\n",
    "        df = create_additional_column_stubs(df, additional_columns)\n",
    "\n",
    "    all_needed_columns = required_columns + additional_columns\n",
    "    df = df[all_needed_columns]\n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72259f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is ready for processing.\n"
     ]
    }
   ],
   "source": [
    "required_columns = [ 'address_number', 'municipality', 'lat',\n",
    "       'lon', 'postal_code', 'street_name', 'province_state', 'country',\n",
    "       'geom']\n",
    "\n",
    "additional_columns = ['address_id', 'pool_type']\n",
    "\n",
    "df = pd.read_csv('/home/james/PDS/client_data_feeds/realestate/moncton_data_prep/moncton_upload.csv')\n",
    "\n",
    "def check_required_columns(df, required_columns):\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    return True\n",
    "\n",
    "def has_additional_columns(df, additional_columns):\n",
    "    present_additional_columns = [col for col in additional_columns if col in df.columns]\n",
    "    return present_additional_columns\n",
    "\n",
    "\n",
    "def create_additional_column_stubs(df):\n",
    "    #check the df does not have address_id\n",
    "    if 'address_id' not in df.columns:\n",
    "        df['address_id'] = generate_address_id()\n",
    "    \n",
    "\n",
    "    if 'pool_type' not in df.columns:\n",
    "        df['pool_type'] = None\n",
    "    return df\n",
    "\n",
    "\n",
    "has_required = check_required_columns(df, required_columns)\n",
    "present_additional = has_additional_columns(df, additional_columns)\n",
    "\n",
    "if not has_required:\n",
    "    raise ValueError(\"DataFrame does not have all required columns.\")\n",
    "\n",
    "if not present_additional:\n",
    "    df = create_additional_column_stubs(df, additional_columns)\n",
    "\n",
    "print(\"DataFrame is ready for processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c6df578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any columns not in required or additional columns\n",
    "all_needed_columns = required_columns + additional_columns\n",
    "df = df[all_needed_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08479fd",
   "metadata": {},
   "source": [
    "## Step 2: NaN Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7421a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def cleanup_dataframe(df):\n",
    "        # NAN Checks: \n",
    "    indexes_with_missing_values = set()\n",
    "\n",
    "    for col in required_columns:\n",
    "        missing_in_col = df[df[col].isnull() | (df[col] == '')].index\n",
    "        indexes_with_missing_values.update(missing_in_col)\n",
    "\n",
    "    # drop rows with missing values in required columns\n",
    "    df_cleaned = df.drop(indexes_with_missing_values)\n",
    "    CA_POSTAL_RE = re.compile(\n",
    "        r\"\\b[ABCEGHJ-NPRSTVXY]\\d[ABCEGHJ-NPRSTV-Z][ -]?\\d[ABCEGHJ-NPRSTV-Z]\\d\\b\",\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    def is_valid_canadian_postal_code(postal_code):\n",
    "        if pd.isnull(postal_code):\n",
    "            return False\n",
    "        return bool(CA_POSTAL_RE.fullmatch(postal_code.strip()))\n",
    "\n",
    "    # validate postal codes\n",
    "    invalid_postal_indexes = df_cleaned[~df_cleaned['postal_code'].apply(is_valid_canadian_postal_code)].index\n",
    "\n",
    "    # drop rows with invalid postal codes\n",
    "    df_clean_postal = df_cleaned.drop(invalid_postal_indexes)\n",
    "\n",
    "    return df_clean_postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c62df45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with missing required values.\n"
     ]
    }
   ],
   "source": [
    "# check each of the required columns for null, None, or empty string values\n",
    "indexes_with_missing_values = set()\n",
    "\n",
    "for col in required_columns:\n",
    "    missing_in_col = df[df[col].isnull() | (df[col] == '')].index\n",
    "    indexes_with_missing_values.update(missing_in_col)\n",
    "\n",
    "# drop rows with missing values in required columns\n",
    "df_cleaned = df.drop(indexes_with_missing_values)\n",
    "\n",
    "print(f\"Dropped {len(indexes_with_missing_values)} rows with missing required values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad372df",
   "metadata": {},
   "source": [
    "## Step 3: Validity check on Postal Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5736e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "CA_POSTAL_RE = re.compile(\n",
    "    r\"\\b[ABCEGHJ-NPRSTVXY]\\d[ABCEGHJ-NPRSTV-Z][ -]?\\d[ABCEGHJ-NPRSTV-Z]\\d\\b\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def is_valid_canadian_postal_code(postal_code):\n",
    "    if pd.isnull(postal_code):\n",
    "        return False\n",
    "    return bool(CA_POSTAL_RE.fullmatch(postal_code.strip()))\n",
    "\n",
    "# validate postal codes\n",
    "invalid_postal_indexes = df_cleaned[~df_cleaned['postal_code'].apply(is_valid_canadian_postal_code)].index\n",
    "\n",
    "# drop rows with invalid postal codes\n",
    "df_clean_postal = df_cleaned.drop(invalid_postal_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6eeda0",
   "metadata": {},
   "source": [
    "# Ennsure that all lat-lons are in the same hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53d3cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lat_lon_in_same_hemisphere(df):\n",
    "    # reject if we have both + and - latitudes or longitudes\n",
    "    latitudes = df['lat']\n",
    "    longitudes = df['lon']\n",
    "\n",
    "    if (latitudes > 0).any() and (latitudes < 0).any():\n",
    "        return False\n",
    "    if (longitudes > 0).any() and (longitudes < 0).any():\n",
    "        return False\n",
    "    \n",
    "\n",
    "    return True\n",
    "\n",
    "has_consistent_hemisphere = check_lat_lon_in_same_hemisphere(df_clean_postal)\n",
    "\n",
    "if not has_consistent_hemisphere:\n",
    "    raise ValueError(\"Latitude and Longitude values are not in the same hemisphere.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a8ff4",
   "metadata": {},
   "source": [
    "## Internal Duplicate Removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37999bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we standardize the postal codes, as well as street_name and municipality to uppercase and strip whitespace\n",
    "def standardize_text_fields(df):\n",
    "    df['postal_code'] = df['postal_code'].str.upper().str.replace(' ', '', regex=False)\n",
    "    df['street_name'] = df['street_name'].str.strip().str.title()\n",
    "    df['municipality'] = df['municipality'].str.strip().str.title()\n",
    "    return df\n",
    "df_clean_postal = standardize_text_fields(df_clean_postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29537bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicates where street_name AND address_number match, along with EITHER municipality OR postal code\n",
    "mask = df_clean_postal.duplicated(subset=['street_name', 'address_number', 'municipality'], keep='first') | \\\n",
    "    df_clean_postal.duplicated(subset=['street_name', 'address_number', 'postal_code'], keep='first')\n",
    "\n",
    "df_final = df_clean_postal[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    # Drop duplicates where street_name AND address_number match, along with EITHER municipality OR postal code\n",
    "    mask = df.duplicated(subset=['street_name', 'address_number', 'municipality'], keep='first') | \\\n",
    "        df.duplicated(subset=['street_name', 'address_number', 'postal_code'], keep='first')\n",
    "    df_no_duplicates = df[~mask]\n",
    "    return df_no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbd052",
   "metadata": {},
   "source": [
    "## Now we de-duplicate with the db. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27390aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from geopy.distance import distance\n",
    "from shapely import box\n",
    "\n",
    "def build_bbox(df):\n",
    "\n",
    "    min_lat = df['lat'].min()\n",
    "    max_lat = df['lat'].max()\n",
    "    min_lon = df['lon'].min()\n",
    "    max_lon = df['lon'].max()\n",
    "    bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "    #add a 5 km buffer to the bbox\n",
    "    buffer_km = 5\n",
    "\n",
    "    # import geopy to calculate the buffer\n",
    "\n",
    "    bottom_left = (min_lat, min_lon)\n",
    "    top_right = (max_lat, max_lon)\n",
    "    bottom_left_buffered = distance(kilometers=buffer_km).destination(bottom_left, 225)  # 225 degrees is southwest\n",
    "    top_right_buffered = distance(kilometers=buffer_km).destination(top_right,45)    # 45 degrees is northeast\n",
    "    bbox_buffered = (bottom_left_buffered.longitude, bottom_left_buffered.latitude,\n",
    "                    top_right_buffered.longitude, top_right_buffered.latitude)\n",
    "\n",
    "\n",
    "\n",
    "    return bbox_buffered\n",
    "\n",
    "bbox_buffered = build_bbox(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MASTER_DB_URL=''\n",
    "conn = get_master_db_connection(MASTER_DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb14561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/gdal_env/lib/python3.10/site-packages/geopandas/io/sql.py:185: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 23 addresses from master database within bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/gdal_env/lib/python3.10/site-packages/geopandas/io/sql.py:473: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(spatial_ref_sys_sql, con)\n"
     ]
    }
   ],
   "source": [
    "# now we query the master db to get all addresses within the bbox\n",
    "query = f\"\"\"\n",
    "SELECT * FROM properties WHERE ST_Intersects(geom, ST_MakeEnvelope({bbox_buffered[0]}, {bbox_buffered[1]}, {bbox_buffered[2]}, {bbox_buffered[3]}, 4326));\n",
    "\"\"\"\n",
    "master_addresses = gpd.read_postgis(query, conn, geom_col='geom')\n",
    "print(f\"Retrieved {len(master_addresses)} addresses from master database within bounding box.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "160b92c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>address_id</th>\n",
       "      <th>address_number</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>street_name</th>\n",
       "      <th>municipality</th>\n",
       "      <th>province_state</th>\n",
       "      <th>geom</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b4f96c2-48a0-462b-b388-e6e4587865f6</td>\n",
       "      <td>8980286175673212036</td>\n",
       "      <td>287</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.096984</td>\n",
       "      <td>-64.714013</td>\n",
       "      <td>E1A7W9</td>\n",
       "      <td>Manon Street</td>\n",
       "      <td>Dieppe</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>POINT (-64.71401 46.09698)</td>\n",
       "      <td>2026-01-28 20:35:16.413808+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56080f32-f758-4ff7-8c07-cc6cdd7fd648</td>\n",
       "      <td>2385072820701278606</td>\n",
       "      <td>58</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.084448</td>\n",
       "      <td>-64.823529</td>\n",
       "      <td>E1E3X2</td>\n",
       "      <td>Briarwood</td>\n",
       "      <td>Moncton</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>POINT (-64.82353 46.08445)</td>\n",
       "      <td>2026-01-28 20:35:16.413808+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9c40a96-d689-4194-999b-a9f7d0365283</td>\n",
       "      <td>6735574806161078946</td>\n",
       "      <td>41</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.077931</td>\n",
       "      <td>-64.708625</td>\n",
       "      <td>E1A8A1</td>\n",
       "      <td>Cyr Street</td>\n",
       "      <td>Dieppe</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>POINT (-64.70862 46.07793)</td>\n",
       "      <td>2026-01-28 20:35:16.413808+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520e8ca3-bcd0-4885-8763-cc4bc89b8d7d</td>\n",
       "      <td>2110689378835180626</td>\n",
       "      <td>11</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.053524</td>\n",
       "      <td>-64.782852</td>\n",
       "      <td>E1B0R5</td>\n",
       "      <td>Rosebank Crescent</td>\n",
       "      <td>Riverview</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>POINT (-64.78285 46.05352)</td>\n",
       "      <td>2026-01-28 20:35:16.413808+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a00270de-3579-40b9-aa66-6d31b0425830</td>\n",
       "      <td>5841912189221429131</td>\n",
       "      <td>424</td>\n",
       "      <td>Canada</td>\n",
       "      <td>46.107994</td>\n",
       "      <td>-64.749371</td>\n",
       "      <td>E1A2T1</td>\n",
       "      <td>Shediac Road</td>\n",
       "      <td>Moncton</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>POINT (-64.74937 46.10799)</td>\n",
       "      <td>2026-01-28 20:35:16.413808+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id           address_id address_number  \\\n",
       "0  4b4f96c2-48a0-462b-b388-e6e4587865f6  8980286175673212036            287   \n",
       "1  56080f32-f758-4ff7-8c07-cc6cdd7fd648  2385072820701278606             58   \n",
       "2  f9c40a96-d689-4194-999b-a9f7d0365283  6735574806161078946             41   \n",
       "3  520e8ca3-bcd0-4885-8763-cc4bc89b8d7d  2110689378835180626             11   \n",
       "4  a00270de-3579-40b9-aa66-6d31b0425830  5841912189221429131            424   \n",
       "\n",
       "  country        lat        lon postal_code        street_name municipality  \\\n",
       "0  Canada  46.096984 -64.714013      E1A7W9       Manon Street       Dieppe   \n",
       "1  Canada  46.084448 -64.823529      E1E3X2          Briarwood      Moncton   \n",
       "2  Canada  46.077931 -64.708625      E1A8A1         Cyr Street       Dieppe   \n",
       "3  Canada  46.053524 -64.782852      E1B0R5  Rosebank Crescent    Riverview   \n",
       "4  Canada  46.107994 -64.749371      E1A2T1       Shediac Road      Moncton   \n",
       "\n",
       "  province_state                        geom                       updated_at  \n",
       "0  New Brunswick  POINT (-64.71401 46.09698) 2026-01-28 20:35:16.413808+00:00  \n",
       "1  New Brunswick  POINT (-64.82353 46.08445) 2026-01-28 20:35:16.413808+00:00  \n",
       "2  New Brunswick  POINT (-64.70862 46.07793) 2026-01-28 20:35:16.413808+00:00  \n",
       "3  New Brunswick  POINT (-64.78285 46.05352) 2026-01-28 20:35:16.413808+00:00  \n",
       "4  New Brunswick  POINT (-64.74937 46.10799) 2026-01-28 20:35:16.413808+00:00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0671bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows that matched existing addresses in master database.\n"
     ]
    }
   ],
   "source": [
    "# first we drop any rows from df if address_id matches one in master_addresses\n",
    "inital_row_count = len(df_final)\n",
    "df_final = df_final[~df_final['address_id'].isin(master_addresses['address_id'])]\n",
    "\n",
    "# use standardization on master_addresses as well\n",
    "master_addresses = standardize_text_fields(master_addresses)\n",
    "\n",
    "# next we drop rows where street_name AND address_number match, along with EITHER municipality OR postal code in master_addresses\n",
    "\n",
    "\n",
    "\n",
    "mask = df_final.apply(\n",
    "    lambda row: (\n",
    "        ((master_addresses['street_name'] == row['street_name']) &\n",
    "         (master_addresses['address_number'] == row['address_number']) &\n",
    "         (master_addresses['municipality'] == row['municipality'])).any() or\n",
    "        ((master_addresses['street_name'] == row['street_name']) &\n",
    "         (master_addresses['address_number'] == row['address_number']) &\n",
    "         (master_addresses['postal_code'] == row['postal_code'])).any()\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_final_unique = df_final[~mask]\n",
    "final_row_count = len(df_final_unique)\n",
    "dropped_due_to_master = inital_row_count - final_row_count\n",
    "print(f\"Dropped {dropped_due_to_master} rows that matched existing addresses in master database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_df, master_df):\n",
    "    # Drop duplicates where street_name AND address_number match, along with EITHER municipality OR postal code in master_df\n",
    "    mask = input_df.apply(\n",
    "        lambda row: (\n",
    "            ((master_df['street_name'] == row['street_name']) &\n",
    "             (master_df['address_number'] == row['address_number']) &\n",
    "             (master_df['municipality'] == row['municipality'])).any() or\n",
    "            ((master_df['street_name'] == row['street_name']) &\n",
    "             (master_df['address_number'] == row['address_number']) &\n",
    "             (master_df['postal_code'] == row['postal_code'])).any()\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    df_no_duplicates = input_df[~mask]\n",
    "    return df_no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc121f91",
   "metadata": {},
   "source": [
    "# Upload properties to db. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec6a821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "address_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "municipality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "postal_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "street_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province_state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "geom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "address_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a8f4a2ab-e21b-48b8-a1d9-68fae9a2f79e",
       "rows": [
        [
         "0",
         "595",
         "Dieppe",
         "46.03809929328514",
         "-64.69535435037182",
         "E1A7K6",
         "Dover Road",
         "NB",
         "Canada",
         "POINT(-64.69535435037182 46.03809929328514)",
         "206712"
        ],
        [
         "1",
         "120",
         "Moncton",
         "46.05913287378083",
         "-64.8850753446976",
         "E1B5G1",
         "Acacia Drive",
         "NB",
         "Canada",
         "POINT(-64.8850753446976 46.05913287378083)",
         "206711"
        ],
        [
         "2",
         "26",
         "Dieppe",
         "46.10186259923136",
         "-64.68248518917952",
         "E1A1R5",
         "Lorette Street",
         "NB",
         "Canada",
         "POINT(-64.68248518917952 46.10186259923136)",
         "206715"
        ],
        [
         "3",
         "35",
         "Dieppe",
         "46.10170090063899",
         "-64.67764705740598",
         "E1A1R5",
         "Appleton Street",
         "NB",
         "Canada",
         "POINT(-64.67764705740598 46.10170090063899)",
         "206716"
        ],
        [
         "4",
         "268",
         "Moncton",
         "46.10457231079941",
         "-64.74352927911653",
         "E1A5R8",
         "Highlandview Road",
         "NB",
         "Canada",
         "POINT(-64.74352927911653 46.10457231079941)",
         "206718"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_number</th>\n",
       "      <th>municipality</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>street_name</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country</th>\n",
       "      <th>geom</th>\n",
       "      <th>address_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>595</td>\n",
       "      <td>Dieppe</td>\n",
       "      <td>46.038099</td>\n",
       "      <td>-64.695354</td>\n",
       "      <td>E1A7K6</td>\n",
       "      <td>Dover Road</td>\n",
       "      <td>NB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>POINT(-64.69535435037182 46.03809929328514)</td>\n",
       "      <td>206712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>Moncton</td>\n",
       "      <td>46.059133</td>\n",
       "      <td>-64.885075</td>\n",
       "      <td>E1B5G1</td>\n",
       "      <td>Acacia Drive</td>\n",
       "      <td>NB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>POINT(-64.8850753446976 46.05913287378083)</td>\n",
       "      <td>206711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Dieppe</td>\n",
       "      <td>46.101863</td>\n",
       "      <td>-64.682485</td>\n",
       "      <td>E1A1R5</td>\n",
       "      <td>Lorette Street</td>\n",
       "      <td>NB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>POINT(-64.68248518917952 46.10186259923136)</td>\n",
       "      <td>206715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Dieppe</td>\n",
       "      <td>46.101701</td>\n",
       "      <td>-64.677647</td>\n",
       "      <td>E1A1R5</td>\n",
       "      <td>Appleton Street</td>\n",
       "      <td>NB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>POINT(-64.67764705740598 46.10170090063899)</td>\n",
       "      <td>206716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268</td>\n",
       "      <td>Moncton</td>\n",
       "      <td>46.104572</td>\n",
       "      <td>-64.743529</td>\n",
       "      <td>E1A5R8</td>\n",
       "      <td>Highlandview Road</td>\n",
       "      <td>NB</td>\n",
       "      <td>Canada</td>\n",
       "      <td>POINT(-64.74352927911653 46.10457231079941)</td>\n",
       "      <td>206718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address_number municipality        lat        lon postal_code  \\\n",
       "0             595       Dieppe  46.038099 -64.695354      E1A7K6   \n",
       "1             120      Moncton  46.059133 -64.885075      E1B5G1   \n",
       "2              26       Dieppe  46.101863 -64.682485      E1A1R5   \n",
       "3              35       Dieppe  46.101701 -64.677647      E1A1R5   \n",
       "4             268      Moncton  46.104572 -64.743529      E1A5R8   \n",
       "\n",
       "         street_name province_state country  \\\n",
       "0         Dover Road             NB  Canada   \n",
       "1       Acacia Drive             NB  Canada   \n",
       "2     Lorette Street             NB  Canada   \n",
       "3    Appleton Street             NB  Canada   \n",
       "4  Highlandview Road             NB  Canada   \n",
       "\n",
       "                                          geom  address_id  \n",
       "0  POINT(-64.69535435037182 46.03809929328514)      206712  \n",
       "1   POINT(-64.8850753446976 46.05913287378083)      206711  \n",
       "2  POINT(-64.68248518917952 46.10186259923136)      206715  \n",
       "3  POINT(-64.67764705740598 46.10170090063899)      206716  \n",
       "4  POINT(-64.74352927911653 46.10457231079941)      206718  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we will need to split out and create a separate pool_df\n",
    "\n",
    "\n",
    "POOL_COLUMNS = ['address_id', 'pool_type']\n",
    "pool_df = df_final_unique[POOL_COLUMNS].copy()\n",
    "address_df = df_final_unique.drop(columns='pool_type')\n",
    "address_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f777add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded 2527 addresses to properties table.\n"
     ]
    }
   ],
   "source": [
    "# now we upload address_df to master db using plain SQL\n",
    "from shapely.geometry import Point\n",
    "conn = get_master_db_connection(MASTER_DB_URL)\n",
    "# Ensure geom column has Point geometries\n",
    "if 'geom' not in address_df.columns or address_df['geom'].dtype == 'object':\n",
    "    address_df['geom'] = address_df.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "\n",
    "# Prepare the insert statement\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO properties (address_id, address_number, country, lat, lon, postal_code, \n",
    "                        street_name, municipality, province_state, geom)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, ST_GeogFromText(%s))\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "    rows_inserted = 0\n",
    "    \n",
    "    for idx, row in address_df.iterrows():\n",
    "        # Create WKT representation of the point\n",
    "        wkt = f\"POINT({row['lon']} {row['lat']})\"\n",
    "        \n",
    "        values = (\n",
    "            int(row['address_id']),\n",
    "            row['address_number'],\n",
    "            row['country'],\n",
    "            float(row['lat']),\n",
    "            float(row['lon']),\n",
    "            row['postal_code'],\n",
    "            row['street_name'],\n",
    "            row['municipality'],\n",
    "            row['province_state'],\n",
    "            wkt\n",
    "        )\n",
    "        \n",
    "        cursor.execute(insert_query, values)\n",
    "        rows_inserted += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(f\"Successfully uploaded {rows_inserted} addresses to properties table.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error uploading addresses: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13e2dcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "address_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pool_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pool_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "property_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "50698862-87c3-491a-aaca-784fc154927b",
       "rows": [
        [
         "0",
         "206712",
         "in-ground-pool-closed",
         "3986387544446953920",
         "e8b201de-105c-4cb5-bd25-d477596ffa7c"
        ],
        [
         "1",
         "206711",
         "in-ground-pool-closed",
         "5707433658476730178",
         "05fa2b27-267e-47be-883e-298dea6d4fc5"
        ],
        [
         "2",
         "206715",
         "above-ground-pool-open",
         "4178940787347723104",
         "7a43216a-6050-49fd-aa61-d2ea514f2b19"
        ],
        [
         "3",
         "206716",
         "above-ground-pool-closed",
         "2346899496511946761",
         "6182ffd4-139f-48f7-9118-e28b0a72e376"
        ],
        [
         "4",
         "206718",
         "above-ground-pool-closed",
         "7443731055373392643",
         "e462df0e-2962-4b31-a572-2963d389dee0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_id</th>\n",
       "      <th>pool_type</th>\n",
       "      <th>pool_id</th>\n",
       "      <th>property_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206712</td>\n",
       "      <td>in-ground-pool-closed</td>\n",
       "      <td>3986387544446953920</td>\n",
       "      <td>e8b201de-105c-4cb5-bd25-d477596ffa7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206711</td>\n",
       "      <td>in-ground-pool-closed</td>\n",
       "      <td>5707433658476730178</td>\n",
       "      <td>05fa2b27-267e-47be-883e-298dea6d4fc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206715</td>\n",
       "      <td>above-ground-pool-open</td>\n",
       "      <td>4178940787347723104</td>\n",
       "      <td>7a43216a-6050-49fd-aa61-d2ea514f2b19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206716</td>\n",
       "      <td>above-ground-pool-closed</td>\n",
       "      <td>2346899496511946761</td>\n",
       "      <td>6182ffd4-139f-48f7-9118-e28b0a72e376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206718</td>\n",
       "      <td>above-ground-pool-closed</td>\n",
       "      <td>7443731055373392643</td>\n",
       "      <td>e462df0e-2962-4b31-a572-2963d389dee0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address_id                 pool_type              pool_id  \\\n",
       "0      206712     in-ground-pool-closed  3986387544446953920   \n",
       "1      206711     in-ground-pool-closed  5707433658476730178   \n",
       "2      206715    above-ground-pool-open  4178940787347723104   \n",
       "3      206716  above-ground-pool-closed  2346899496511946761   \n",
       "4      206718  above-ground-pool-closed  7443731055373392643   \n",
       "\n",
       "                            property_id  \n",
       "0  e8b201de-105c-4cb5-bd25-d477596ffa7c  \n",
       "1  05fa2b27-267e-47be-883e-298dea6d4fc5  \n",
       "2  7a43216a-6050-49fd-aa61-d2ea514f2b19  \n",
       "3  6182ffd4-139f-48f7-9118-e28b0a72e376  \n",
       "4  e462df0e-2962-4b31-a572-2963d389dee0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Generate pool_id values for pool_df using time-based hash\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "def generate_time_based_id():\n",
    "    \"\"\"Generate a unique ID based on time and random component\"\"\"\n",
    "    timestamp = str(time.time()).encode()\n",
    "    random_component = str(time.time_ns()).encode()\n",
    "    hash_obj = hashlib.sha256(timestamp + random_component)\n",
    "    # Convert hash to int and ensure it fits in PostgreSQL BIGINT (signed 64-bit)\n",
    "    # Max value for signed bigint is 9223372036854775807\n",
    "    hash_int = int(hash_obj.hexdigest()[:16], 16)\n",
    "    return hash_int % 9223372036854775807\n",
    "\n",
    "# Generate pool_id - always regenerate with new time-based IDs\n",
    "pool_df['pool_id'] = [generate_time_based_id() for _ in range(len(pool_df))]\n",
    "\n",
    "pool_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1756a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 2527 pools to properties\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "address_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pool_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pool_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "property_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "221f2017-82a0-46e3-88c1-e3d4ec7c4237",
       "rows": [
        [
         "0",
         "206712",
         "in-ground-pool-closed",
         "3986387544446953920",
         "e8b201de-105c-4cb5-bd25-d477596ffa7c"
        ],
        [
         "1",
         "206711",
         "in-ground-pool-closed",
         "5707433658476730178",
         "05fa2b27-267e-47be-883e-298dea6d4fc5"
        ],
        [
         "2",
         "206715",
         "above-ground-pool-open",
         "4178940787347723104",
         "7a43216a-6050-49fd-aa61-d2ea514f2b19"
        ],
        [
         "3",
         "206716",
         "above-ground-pool-closed",
         "2346899496511946761",
         "6182ffd4-139f-48f7-9118-e28b0a72e376"
        ],
        [
         "4",
         "206718",
         "above-ground-pool-closed",
         "7443731055373392643",
         "e462df0e-2962-4b31-a572-2963d389dee0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_id</th>\n",
       "      <th>pool_type</th>\n",
       "      <th>pool_id</th>\n",
       "      <th>property_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206712</td>\n",
       "      <td>in-ground-pool-closed</td>\n",
       "      <td>3986387544446953920</td>\n",
       "      <td>e8b201de-105c-4cb5-bd25-d477596ffa7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206711</td>\n",
       "      <td>in-ground-pool-closed</td>\n",
       "      <td>5707433658476730178</td>\n",
       "      <td>05fa2b27-267e-47be-883e-298dea6d4fc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206715</td>\n",
       "      <td>above-ground-pool-open</td>\n",
       "      <td>4178940787347723104</td>\n",
       "      <td>7a43216a-6050-49fd-aa61-d2ea514f2b19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206716</td>\n",
       "      <td>above-ground-pool-closed</td>\n",
       "      <td>2346899496511946761</td>\n",
       "      <td>6182ffd4-139f-48f7-9118-e28b0a72e376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206718</td>\n",
       "      <td>above-ground-pool-closed</td>\n",
       "      <td>7443731055373392643</td>\n",
       "      <td>e462df0e-2962-4b31-a572-2963d389dee0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address_id                 pool_type              pool_id  \\\n",
       "0      206712     in-ground-pool-closed  3986387544446953920   \n",
       "1      206711     in-ground-pool-closed  5707433658476730178   \n",
       "2      206715    above-ground-pool-open  4178940787347723104   \n",
       "3      206716  above-ground-pool-closed  2346899496511946761   \n",
       "4      206718  above-ground-pool-closed  7443731055373392643   \n",
       "\n",
       "                            property_id  \n",
       "0  e8b201de-105c-4cb5-bd25-d477596ffa7c  \n",
       "1  05fa2b27-267e-47be-883e-298dea6d4fc5  \n",
       "2  7a43216a-6050-49fd-aa61-d2ea514f2b19  \n",
       "3  6182ffd4-139f-48f7-9118-e28b0a72e376  \n",
       "4  e462df0e-2962-4b31-a572-2963d389dee0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Get the property UUIDs for the address_ids we just inserted\n",
    "address_ids = pool_df['address_id'].tolist()\n",
    "\n",
    "# Query to get id (UUID) and address_id from properties table\n",
    "query = \"\"\"\n",
    "SELECT id, address_id \n",
    "FROM properties \n",
    "WHERE address_id = ANY(%s)\n",
    "\"\"\"\n",
    "conn = get_master_db_connection(MASTER_DB_URL)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query, (address_ids,))\n",
    "property_mappings = cursor.fetchall()\n",
    "cursor.close()\n",
    "\n",
    "# Create a mapping dict: address_id -> property_id (UUID)\n",
    "address_to_property = {row[1]: row[0] for row in property_mappings}\n",
    "\n",
    "# Add property_id column to pool_df\n",
    "pool_df['property_id'] = pool_df['address_id'].map(address_to_property)\n",
    "\n",
    "# Check if any addresses didn't get mapped\n",
    "unmapped = pool_df[pool_df['property_id'].isnull()]\n",
    "if len(unmapped) > 0:\n",
    "    print(f\"Warning: {len(unmapped)} pools couldn't be mapped to properties\")\n",
    "    print(unmapped)\n",
    "\n",
    "print(f\"Mapped {len(pool_df[pool_df['property_id'].notnull()])} pools to properties\")\n",
    "pool_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6142f83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded 2527 pools to database.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Upload pools to database\n",
    "# Filter out any unmapped pools\n",
    "pool_df_upload = pool_df[pool_df['property_id'].notnull()].copy()\n",
    "\n",
    "# Insert pools\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO pools (pool_id, property_id, pool_type)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "    pools_inserted = 0\n",
    "    \n",
    "    for idx, row in pool_df_upload.iterrows():\n",
    "        values = (\n",
    "            int(row['pool_id']),\n",
    "            row['property_id'],  # This is already a UUID string\n",
    "            row['pool_type'] if pd.notna(row['pool_type']) else None\n",
    "        )\n",
    "        \n",
    "        cursor.execute(insert_query, values)\n",
    "        pools_inserted += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(f\"Successfully uploaded {pools_inserted} pools to database.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error uploading pools: {e}\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
